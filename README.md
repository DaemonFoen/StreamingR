## Требования

Конвейер состоит из связанных между собой узлов. Узел характеризуется набором входных и выходных каналов, по которым могут передаваться объекты. Узел ожидает появления определенного набора объектов на своих входных каналах, после чего проводит вычисления и порождает объект(-ы) на своих выходных каналах (не обязательно всех). При этом, если входные каналы не будут синхронизованы, то в одном из них могут "скапливаться" данные, ожидающие обработки. Определите проблемно-специфичный язык (DSL) для работы с конвейерными схемами обработки данных, поддерживающий следующие элементы:
* узлы с набором входных и выходных каналов;
* статическую типизацию каналов;
* формирование конвейера в форме связанных узлов в соответствии с типизацией;
* параллельное исполнение отдельных узлов конвейера;
* использование одинаковых узлов для формирования разных конвейеров.

Конвейер должен формироваться автоматически на основе DSL путём построения ориентированного графа вычислений (execution graph).
Перед запуском конвейера должна выполняться предварительная обработка DSL, включающая:
* разбор описания конвейера;
* построение абстрактного графа;
* проверку корректности связей между узлами.
  Конвейер не должен запускаться напрямую из DSL, а только после успешного построения execution graph.

Исполнение конвейера **должно осуществляться runtime-движком**, отделённым от слоя описания конвейера.
Runtime-движок **должен обеспечивать**:
* инициализацию узлов;
* связывание узлов каналами передачи данных;
* запуск выполнения конвейера в соответствии со структурой графа.
  Узлы конвейера **должны исполняться независимо друг от друга**, взаимодействуя исключительно через каналы передачи данных.

Из **дополнительных** требований было выполнено:
* настраиваемые узлы, параметры которых можно менять в уже созданном конвейере;
* конвейеры с циклами;
* признак окончания работы конвейера (обратите внимание, что конвейер может
  прийти в состояние, когда его работа никогда не завершится, в этом случае
  необходимо диагностировать ошибку);
* добавлена возможность изменения тела функции обработки записей без пересборки проекта

## Архитектура (предполагаемый путь решения задачи)

В рамках задания будут реализованы следующие архитектурные слои:

1. **Preprocessing слой**

    * разбор DSL (JSON);
    * построение абстрактного execution graph;
    * проверка корректности связей и типов.

2. **Runtime слой**

    * преобразование execution graph в runtime-граф;
    * управление жизненным циклом узлов;
    * запуск и координация исполнения.

3. **Runtime-узлы**

    * базовый интерфейс/абстракция узла;
    * специализированные реализации Source / Transform / Sink.

---

| Исполнитель   | Область ответственности                     | Функциональность |
|---------------|---------------------------------------------|----------------------------------|
| Дима Голенко  | Runtime и архитектура                  | - Реализация runtime-движка исполнения графа<br>- Реализация runtime-узлов (Source / Map / Sink)<br>- Реализация каналов передачи данных<br>- Организация параллельного исполнения узлов<br>- Реализация точки входа и запуска конвейера<br>- Интеграция preprocessing и runtime слоёв |
| Андрей Гудков | Preprocessing слой<br>DSL -> Execution Graph | - Реализация preprocessing-слоя<br>- Парсинг DSL (pipeline.json)<br>- Формирование абстрактного execution graph<br>- Рефакторинг preprocessing-логики и улучшение архитектуры<br>- Выделение ответственности между компонентами preprocessing<br>- Добавление модульных тестов для preprocessing |


## 1) Верхнеуровневое описание

StreamingR - это фреймворк для потоковой обработки данных, в котором описания пайплайнов задаются декларативно в JSON и превращаются в исполняемый граф операторов. Выполнение графа обеспечивается многопоточным рантаймом, который создаёт каналы связи между узлами и управляет жизненным циклом потоков.

Пользователь может описать типы данных, источники и операторы, рантайм парсит описание, строит execution graph, а затем запускает его, последовательно выполняя шаги "парсинг -> построение графа -> развёртывание узлов -> запуск потоков -> сбор результатов".

## 2) Концептуальная модель

- **Pipeline** - JSON-описание типов, источников и операторов (kind, входы/выходы, функции) в терминах `GraphDefinition`. Оно отражает статическую структуру обработки и конфигурацию узлов.
- **Execution graph** - материальное представление pipeline после проверки: узлы `ExecNode` с привязанными портами и конфигурацией и рёбра `ExecEdge`, соединяющие порты с учётом типовой совместимости. Он фиксирует топологию исполнения, но пока не содержит конкретных рантайм-объектов.
- **Типы узлов**. Реализованы `source`, `map`, `sink`.
- **Передача данных** осуществляется через `Channel<T>`, обёртку над `LinkedBlockingQueue` с сигналом окончания `End`. Каждый выходной порт создаёт собственный канал, который связал RuntimeBuilder.
- **Жизненный цикл**: парсинг JSON -> сборка ExecutionGraph -> регистрация типов и развёртывание каналов -> создание рантайм-узлов через фабрики -> запуск отдельных потоков и их join.

## 3) Структура репозитория

```
src/main/java/com/nsu
├── data/                        # доменные типы данных
├── preprocessing/               # парсинг и построение execution graph
├── runtime/                     # рантайм и модели выполнения
└── Main.java                    # точка входа
src/main/resources/pipeline.json # пример pipeline DSL
```

## 4) Pipeline DSL (pipeline.json)

- **Формат**: JSON с тремя верхнеуровневыми разделами `types`, `sources`, `operators`.
- **Типы данных**: описывают `javaType` и возможное наследование через `extends` - например, `JpgImage` расширяет `ImageMeta`. Эти сведения загружаются в `RuntimeTypeRegistry`, чтобы привязывать DSL-имена к реальным классам.
- **Источники**: перечисленные элементы с указанием типа и литеральных значений. `SourceDataFactory` превращает такой список в реальные объекты через Jackson.
- **Операторы**: заданы как именованные сущности с полями `kind`, `inputs`, `outputs`, `funBody`, `config`, `parallelism`. Связи портов задаются ссылками `from`/`to` в формате `<node>.<port>`.
- **Динамический код**: `funBody` вставляется в шаблон Java и компилируется в `DynamicFunctionCompiler` для map-узлов.
- **Использование**: JSON читается `GraphParser`, затем GraphBuilder строит ExecutionGraph, а RuntimeBuilder использует ports/types для прокладки каналов и выбора фабрик.

## 5) Preprocessing слой

- **Роль**: трансформирует DSL-описание в проверенный ExecutionGraph, обеспечивая валидацию ссылок и совместимость типов перед запуском рантайма.
- **Парсинг**: `GraphParser` использует Jackson ObjectMapper для загрузки JSON в `GraphDefinition`.
- **GraphDefinition и ExecutionGraph**: первая хранит декларативные описания типов, операторов и источников, второй - конкретные узлы и рёбра, уже снабжённые портами и метаданными.
- **Построение ExecutionGraph**: GraphBuilder создаёт `ExecNode` для каждого оператора, добавляет порты и переводит ссылки `from/to` в рёбра `ExecEdge`, одновременно проверяя наличие целевых операторов/портов и совместимость типов через `isTypeCompatible`, поддерживающую наследование.
- **Связанные классы**: `Port` и `PortDef` описывают типизированные входы/выходы, а типы `TypeDef` позволяют проверять цепочки наследования при стыковке.

## 6) Runtime слой

- **Архитектура**: `RuntimeBuilder` материализует ExecutionGraph в `RuntimeGraph`, прокладывая каналы и создавая runtime-узлы через реестр фабрик. `RuntimeGraph` управляет коллекцией узлов и связанных потоков.
- **RuntimeGraph**: хранит упорядоченные узлы и для каждого создаёт отдельный `Thread`, что обеспечивает конкурентное выполнение, и предоставляет методы `start()`/`join()` для контроля жизненного цикла.
- **RuntimeBuilder и registry**: при сборке рантайма создаются каналы для каждой дуги, затем подбирается `RuntimeNodeFactory` по `kind` и сигнатурам портов. Регистрация типов происходит через `RuntimeTypeRegistry`, который заводит отображение DSL-имени типа на Java-класс.
- **Создание узлов**: список доступных фабрик сейчас жёстко зашит (source/map/sink для ImageMeta/JpgImage) в `RuntimeBuilder.factories`. Каждая фабрика реализует соглашение `RuntimeNodeFactory`.
- **Выполнение графа**: после сборки `RuntimeGraph` запускается, и каждый `RuntimeNode` исполняется в своём потоке до получения сигнала окончания (нулевой элемент из `Channel`) либо выбрасывания исключения.
- **Механизм запуска/завершения**: сигнал окончания передаётся через `Channel.end()` с использованием маркера `End.INSTANCE`, что позволяет корректно размечать конец потока данных при нескольких потребителях.

## 7) Узлы и каналы

- **SourceNode**: читает заранее подготовленные элементы (итератор) и публикует их в канал, после чего закрывает выход через `end()`.
- **MapNode**: блокирующе читает вход, применяет функцию (либо identity, либо скомпилированную из `funBody`) и пишет результат в выход; при получении `null` закрывает downstream.
- **SinkNode**: считывает вход до сигнала окончания, печатает данные и сообщает о завершении.
- **Channel**: обеспечивает потокобезопасный обмен, типизацию по Java-классу и проброс конечного маркера, что позволяет нескольким узлам корректно завершаться.
- **Потоковость**: каждый узел запускается в отдельном `Thread` на стороне RuntimeGraph, поэтому pipeline обрабатывает данные конвейерно по мере доступности. SelectNode демонстрирует задел для агрегации из нескольких входов с пользовательским `Comparator`.

## 8) Тестирование

- Покрытие preprocessing-слоя: `GraphParserTest` проверяет разбор типов, источников и связей операторов из `pipeline.json`, а также корректность ссылок портов.
- Валидация построения графа: `GraphBuilderTest` создает синтетические операторы и проверяет как успешное соединение, так и ошибки при неизвестных операторах, портах, несовместимых типах и неверном формате ссылок.
- Данные источников: `SourceDataFactoryTest` убеждается, что конвертация DSL-описаний в объекты сохраняет порядок, поддерживает пустые значения и корректно падает при неизвестных типах.
- Регистрация типов: `RuntimeTypeRegistryTest` тестирует загрузку Java-классов, обработку ошибок ClassNotFound и семантику `isAssignable` для разных комбинаций типов.
- Для тестов используется кастомный `pipeline.json`, идентичный основному примеру и обеспечивающий стабильные входные данные для сценариев.
